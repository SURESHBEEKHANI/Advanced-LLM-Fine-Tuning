{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Advanced-LLM-Fine-Tuning/blob/main/finetuning_with_unsloth_using.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  **Installing Necessary Libraries**"
      ],
      "metadata": {
        "id": "VCpOOUVz-Nrb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wISV71ET__ZA",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Upgrade pip to the latest version to ensure compatibility with modern packages\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# Install the \"unsloth\" package from its GitHub repository with support for CUDA 12.1 and PyTorch 2.4.0\n",
        "!pip install \"unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "\n",
        "# Install the xFormers library from Facebook's GitHub repository for optimized transformer computations\n",
        "!pip install https://github.com/facebookresearch/xformers\n",
        "\n",
        "# Install the latest version of Hugging Face's Transformers library directly from its GitHub repository\n",
        "!pip install \"git+https://github.com/huggingface/transformers.git\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.13.1 torchvision==0.14.1"
      ],
      "metadata": {
        "id": "d-V7_8xtCvDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "OKHqR6BrMfoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Uninstall Specific Versions of PyTorch and TorchAudio**"
      ],
      "metadata": {
        "id": "-ukHv3r__zUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the \"trl\" library (Transformers Reinforcement Learning) for implementing reinforcement learning\n",
        "# algorithms using Hugging Face's Transformers library.\n",
        "!pip install trl\n",
        "\n",
        "# Install the \"xformers\" library, which provides optimized and efficient implementations for transformer models,\n",
        "# helping improve memory and computational efficiency.\n",
        "!pip install xformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lv5ZhWZjA-YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove specific versions of PyTorch, TorchAudio, and other related libraries to address version conflicts or prepare for a clean reinstallation:\n",
        "# - `torch==2.1.0`: Removes PyTorch version 2.1.0.\n",
        "# - `torchaudio==2.4.1+cu121`: Removes TorchAudio version 2.4.1, which includes CUDA 12.1\n",
        "!pip uninstall torch==2.1.0 torchaudio==2.4.1+cu121"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaCp9PPJKJWc",
        "outputId": "f35ec3ec-85f1-4483-d3bd-358372dd5ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.4.1\n",
            "Uninstalling torch-2.4.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.10/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch-2.4.1.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils import move_cache\n",
        "move_cache()"
      ],
      "metadata": {
        "id": "FCzbK03tDeYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the PyTorch library, which provides tools for deep learning and tensor computations\n",
        "import torch\n",
        "\n",
        "# Print the currently installed version of PyTorch\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "m5SIqHBSMAG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the IMDB Dataset with the `datasets` Library"
      ],
      "metadata": {
        "id": "W2eb4XWGHCcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the `load_dataset` function from the `datasets` library, which is used for loading and managing datasets.\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the IMDB dataset with the \"train\" split.\n",
        "# The IMDB dataset is commonly used for sentiment analysis tasks, and the \"train\" split contains training examples.\n",
        "dataset = load_dataset(\"imdb\", split=\"train\")"
      ],
      "metadata": {
        "id": "2zpoYqfpFlgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "3D3yzotbGxic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first data sample\n",
        "print(dataset[0])\n",
        "# Output: {'text': 'Example review text...', 'label': 0}"
      ],
      "metadata": {
        "id": "T6BLSVcQCA1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "UDvLPJJKHV0Z",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0].get(\"text\")"
      ],
      "metadata": {
        "id": "f7Cg2ljZHY0s",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0].get(\"label\")"
      ],
      "metadata": {
        "id": "2GJW3e1kHbZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "c7hHn0wqH6Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the `SFTTrainer` class from the `trl` library.\n",
        "# `SFTTrainer` (Supervised Fine-Tuning Trainer) is used for fine-tuning transformer models on labeled datasets.\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# Import `TrainingArguments` from the `transformers` library.\n",
        "# `TrainingArguments` is used to define hyperparameters and settings for training transformer models.\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# Import `FastLanguageModel` from the `unsloth` library.\n",
        "# `FastLanguageModel` is a utility for efficiently loading and working with language models,\n",
        "# optimized for high-speed training and inference.\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# Import the `torch` library, which is used for tensor computations and deep learning.\n",
        "import torch"
      ],
      "metadata": {
        "id": "euk4B784Hpnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the maximum sequence length for the model's input\n",
        "max_seq_length = 2048  # This specifies that the model will process input sequences up to 2048 tokens long"
      ],
      "metadata": {
        "id": "wlt_a9rUMxOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model  load with quantization\n"
      ],
      "metadata": {
        "id": "MuTBe9R4Sg-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained language model using the 'FastLanguageModel' class\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/mistral-7b-bnb-4bit\",  # Specify the model to load by its name or path\n",
        "    max_seq_length = max_seq_length,  # Set the maximum sequence length for the model's input\n",
        "    dtype=None,  # Optionally specify the data type of the model, None means using the default data type\n",
        "    load_in_4bit=True  # Load the model in 4-bit precision to save memory and accelerate inference\n",
        ")"
      ],
      "metadata": {
        "id": "wDJoBYbhHuG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "VzZmkz_3M43u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "id": "PFIWUKLANZhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Configure LoRA with Quantized Model**\n"
      ],
      "metadata": {
        "id": "GZoNQPb2STiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply PEFT (Parameter-Efficient Fine-Tuning) to the pre-loaded model\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,  # Pass the pre-loaded model to apply PEFT\n",
        "    r=16,  # Set the rank (number of parameters to be fine-tuned) for the PEFT layers\n",
        "    lora_alpha = 16,  # Set the scaling factor for the low-rank adaptation (LoRA)\n",
        "    lora_dropout = 0,  # Set the dropout rate for LoRA, here it's 0 (no dropout)\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "    ],  # Specify the model's layers to apply PEFT to (attention projection layers and other components)\n",
        "    bias = \"none\",  # Specify that no bias terms will be applied during PEFT\n",
        "    use_gradient_checkpointing = True,  # Enable gradient checkpointing to reduce memory usage during training\n",
        "    random_state = 3407,  # Set a random seed for reproducibility in training/fine-tuning\n",
        "    max_seq_length = max_seq_length  # Set the maximum sequence length for the model's input\n",
        ")\n"
      ],
      "metadata": {
        "id": "TTz5JC2fNbD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TrainingArguments Configuration**\n"
      ],
      "metadata": {
        "id": "Z8qOKroUH6f9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_argument = TrainingArguments(\n",
        "    per_device_train_batch_size=2,               # Batch size per device for training\n",
        "    gradient_accumulation_steps=4,               # Number of steps to accumulate gradients\n",
        "    warmup_steps=10,                             # Number of steps for the warmup phase\n",
        "    max_steps=60,                                # Maximum number of training steps\n",
        "    fp16=not torch.cuda.is_bf16_supported(),     # Use mixed-precision training with FP16 if BF16 is not supported\n",
        "    bf16=torch.cuda.is_bf16_supported(),         # Use BF16 if supported by the hardware\n",
        "    logging_steps=1,                             # Logging interval (in steps)\n",
        "    output_dir=\"unsloth-test\",                   # Directory to save model checkpoints and logs\n",
        "    optim=\"adamw_8bit\",                          # Optimizer (AdamW with 8-bit precision)\n",
        "    seed=3407                                    # Random seed for reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "ETf2tbPTTGh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SFTTrainer Initialization"
      ],
      "metadata": {
        "id": "9LpM_2XZIioT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the SFTTrainer with the following parameters:\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,                           # The model to be trained (e.g., a pre-trained transformer model)\n",
        "    train_dataset=dataset,                 # The dataset to be used for training\n",
        "    dataset_text_field=\"text\",             # The field in the dataset containing the input text\n",
        "    tokenizer=tokenizer,                   # The tokenizer to preprocess the text data\n",
        "    args=training_argument,                # The training arguments that define the training configuration (e.g., batch size, learning rate, etc.)\n",
        "    max_seq_length=max_seq_length          # The maximum sequence length for the input data (limits the length of tokenized input)\n",
        ")"
      ],
      "metadata": {
        "id": "y29oPgmVSkui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model with `trainer.train()`"
      ],
      "metadata": {
        "id": "ejQJQT8mJS3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Xl-JJlwbToLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review=\"i really liked this movie because it shows emotions with love can you tell me weather it is a postivie review or negative review\""
      ],
      "metadata": {
        "id": "5Nr1-_T6T6VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=tokenizer([\n",
        "    review\n",
        "  ],\n",
        "  return_tensors=\"pt\",\n",
        "  padding=True,\n",
        "  ).to(\"cuda\")"
      ],
      "metadata": {
        "id": "PP9oZfz6UTTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input"
      ],
      "metadata": {
        "id": "mJJNnYVQUp6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=FastLanguageModel.for_inference(model)"
      ],
      "metadata": {
        "id": "BQoWf25hYXVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=model.generate(**input,max_new_tokens=128, use_cache=True)"
      ],
      "metadata": {
        "id": "yT440O9wUp9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "-SzOlm1gUzXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.batch_decode(output)[0]"
      ],
      "metadata": {
        "id": "8Qe2kJK2U0eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i really liked this movie because it shows emotions with love can you tell me weather it is a postivie review or negative review?\n",
        "\n",
        "i really liked this movie because it shows emotions with love can you tell me weather it is a postivie review or negative review?\n",
        "\n",
        "I really liked this movie because it shows emotions with love can you tell me weather it is a postivie review or negative review?\n",
        "\n",
        "I really liked this movie because it shows emotions with love can you tell me weather it is a postivie review or negative review?\n",
        "\n",
        "I really liked this movie because it shows emotions with love can you tell me weather it is a postivie review or negative review?\n",
        "\n",
        "I really liked this movie because it shows emotions"
      ],
      "metadata": {
        "id": "wMx61AKbZHEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i really liked this movie because it shows emotions with love, hate, and jealousy. it also shows how a person can be so blinded by love that they can't see what is right in front of them. i also liked the fact that it was a love story that was not a romance. it was a love story that was about a man who loved a woman so much that he would do anything for her. i also liked the fact that it was a love story that was not a romance. it was a love story that was about a man who loved a woman so much that he would do anything for her. i also liked the fact that it was a love story that"
      ],
      "metadata": {
        "id": "1qVuDOvgYxko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"lora_model\")"
      ],
      "metadata": {
        "id": "WlHUsvTVU0g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "BjJY8DqUU0kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "TXA3fDJFU0nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "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"
      ],
      "metadata": {
        "id": "wRyghLcIaajL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "o4B7elcgZtuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "E0h03iTSailq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN=userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "9xQX7bOGbaxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HF_TOKEN\"]=\"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\""
      ],
      "metadata": {
        "id": "Dm-UTikXacQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export \"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\""
      ],
      "metadata": {
        "id": "ukPsGBFab-44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"sunny199/unsloth_4bit_mistral_imdb_model\",token=\"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\")"
      ],
      "metadata": {
        "id": "GUmC8XnLZuwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(repo_id=\"sunny199/unsloth\",auth=True)"
      ],
      "metadata": {
        "id": "-Npbdk1RaJ1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S51us4tsbJWv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}